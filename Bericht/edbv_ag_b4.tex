%%Berichtvorlage für EDBV WS 2014/2015

\documentclass[deutsch]{scrartcl}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{algorithmic}
%%\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{multirow}
\usepackage{color}\usepackage[width=122mm,left=12mm,paperwidth=146mm,height=193mm,top=12mm,paperheight=217mm]{geometry}

\begin{document}

\title{Image Stitching} 

\subtitle{EDBV WS 2014/2015: AG\_B4} 

%%Namen und Matrikelnummern der Gruppenmitglieder hier eintragen
\author{J. Sebastian Kirchner (0926076)\\
	Hanna Huber (0925230)\\
	Patrick Wahrmann (1327120)\\
	Ernad Sehic (1227865)\\
	Nikolaus Leopold (1327344)}

%%------------------------------------------------------

\maketitle

%%------------------------------------------------------
\section{Gewählte Problemstellung}
(1-1,5 Seiten)\\
entspricht dem (aktualisierten) Konzept
\subsection{Ziel}
Das Ziel ist es zwei Bilder mit überlappenden Bildbereichen (also gleiche Szene mit horizontal verschobener Kamera) anhand von in beiden Bildern vorhandenen Bildmerkmalen (Interest Points) zu einem Bildmosaik zusammenzufügen, sodass die zusammengehörenden Interest Points übereinanderliegen.

\subsection{Eingabe}
Als Eingabedaten werden zwei Bilddateien im Format JPEG oder PNG, die die unten beschriebenen Voraussetzungen erfüllen, verwendet.

\subsection{Ausgabe}
Das Ergebnis ist ein Bildmosaik im selben Format wie die Eingabebilder, das aus Transformation der Einzelbilder entsteht, sodass die gemeinsamen Merkmale übereinstimmen.

\subsection{Voraussetzungen und Bedingungen}
Der Einfachheit halber werden folgende Eigenschaften der Eingabebilder vorausgesetzt:
\begin{itemize}
	\item Die Bilder sind Abbildungen der gleichen Szene, die nur horizontal versetzt sind
	\item Es müssen überlappende Bereiche in den Bildern vorhanden sein, die kontrastreiche Interest Points aufweisen
	\item Die Belichtungsverhältnisse müssen in beiden Bildern möglichst gleich sein (ähnliche Zeit, Ausrichtung bezüglich der Lichtquelle, gleiche Kamera!)
	\item Perspektivische Verzerrungen sollten möglichst vermieden werden, indem entfernte Motive verwendet werden und die Brennweite möglichst hoch gewählt wird.
	\item Möglichst anorganische Strukturen mit klaren Umrissen als zentrales Motiv (Bäume etc. nur am Rande)
	\item Keine beweglichen Objekte, durch die Interests Points verdeckt werden könnten.
\end{itemize}

\subsection{Methodik}
Der folgende Verfahrensablauf wurde implementiert:
\begin{itemize}
	\item Die Bilder werden eingelesen.
	\item Dann wird eine Bildpyramide (Difference of Gaussian, kurz DoG) für SIFT aufgebaut, mittels wiederholt ausgeführtem Gauss-Filter und Downsampling.
	\item Mithilfe der Bildpyramide werden Extrempunkte gefunden (Minima und Maxima der DoG Bilder).
	\item Unpassende Extrempunkte (geringer Kontrast, Kanten) werden entfernt, die verbleibenden Extrema sind die gesuchten Keypoints.
	\item Für Rotationsinvarianz werden die Keypoint-Umgebungsorientierungen bestimmt.
	\item In der Folge werden mittels SIFT die Keypoint-Deskriptoren erstellt.
	\item Korrespondierende Keypoints werden gefunden und zu Merkmalspaaren zusammengefasst.
	\item Mittels RANSAC (Random Sample Consensus) wird die homographische Transformationsmatrix ermittelt, mit der die Bilder so überandergelegt werden, dass die korrespondierenden Keypoints übereinstimmen.
\end{itemize}

Weiters wurde ein GUI implementiert.

\subsection{Evaluierungsfragen}
\begin{itemize}
	\item Werden sinnvolle Merkmale gefunden?
	\item Werden übereinstimmende Bildpaare gefunden?
	\item Werden die Bilder korrekt zusammengefügt?
	\item Hat die Auflösung der Eingabebilder einen merklichen Einfluss auf das Ergebnis?
	\item Welche Bilddaten / Szenen sind ungünstig für den Erfolg des Verfahrens?
	\item Ist das GUI intuitiv aufgebaut?
\end{itemize}


%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\section{Arbeitsteilung}
(0,5 Seiten)\\
Wer hat welche Aufgaben übernommen (MATLAB-Funktionen, Abschnitt im Bericht, Evaluierung, Datenerfassung, etc.)?\\\\
Evaluierung, Datenerfassung, sowie Teile der Funktionalität und des Berichts wurden gemeinsam erarbeitet. Die folgende Tabelle zeigt die Haupt-Aufgabenbereiche, d.h. zu den genannten Themen wurden die entsprechenden Matlab-Funktionen und Abschnitte im Bericht erstellt.
\begin{center}
  \begin{tabular}{ |l|l| }
    \hline
  Name (alphabetisch) & Tätigkeiten\\
    \hline
    \multirow{3}{*}{Hanna Huber} & Keypoint-Matching (RANSAC)\\ & Stitching der Bilder\\ & Multi-Resolution-Spline für weiche Bildverläufe\\ \hline
    \multirow{3}{*}{Sebastian Kirchner} & Entfernung von Keypoints die Kanten darstellen\\  & Anzeige von Keypoints und Matching\\ & Scale-Space-Erzeugung (DoGs)\\\hline
    \multirow{2}{*}{Nikolaus Leopold} & Bestimmung der Keypoint-Umgebungsorientierungen\\ & Erstellung der SIFT-Deskriptoren\\ \hline
    \multirow{1}{*}{Ernad Sehic} & Scale-Space-Erzeugung (DoGs)\\ \hline
    \multirow{3}{*}{Patrick Wahrmann} & Bestimmung der Scale-Space-Extrempunkte\\ & Entfernung von Keypoints mit geringem Kontrast\\ & GUI\\ \hline
  \end{tabular}
\end{center}

%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\section{Methodik}
Ein wesentlicher Teil des Image Stitching ist die Korrespondenzanalyse. Dabei werden für den überlappenden Bereich der Bilder jene Bildpunkte in beiden Bildern gesucht, die dasselbe Objekt darstellen. Dieses Problem wird mithilfe von merkmalbasiertem Matching gelöst, das gegenüber regionenbasiertem Matching den Vorteil hat, dass homogene und daher irrelevante Bildbereiche nicht in die Berechnung mit einfließen. Der Aufwand wird dadurch erheblich reduziert. \cite{evc14} \\
Die Merkmale - Interest Points oder Keypoints - werden mittels Scale Invariant Feature Transform (kurz: SIFT) \cite{lowe04} gefunden. Dieser Algorithmus hat den Vorteil, dass das Ergebnis unabhängig von der Skalierung oder Orientierung der Interest Points im jeweiligen Bild ist \cite{evc14}.

\subsection{SIFT}
Der SIFT-Algorithmus ist in mehrere Schritte unterteilt, in denen Skalierung, Position und Orientierung der Interest Points ermittelt wird. Abschließend muss jeder Punkt eindeutig beschrieben werden, um die Korrespondenzanalyse zu ermöglichen.

\subsubsection{Bildpyramiden}
Um die Skalierungsinvarianz zu garantieren, ist eine Multiskalenanalyse der Bilder notwendig. Im Zuge dessen wird eine Bildpyramide aufgebaut, bestehend aus 4 Oktaven mit jeweils 5 Frequenzstufen. Von Oktave zu Oktave wird die Auflösung des Bildes halbiert und innerhalb der Oktaven wird iterativ gefiltert. \\
Ausgehend von dieser Bildpyramide werden nun pro Oktave 4 DoG-Bilder erstellt indem sukzessive die Differenz der gefilterten Bilder berechnet wird. 

\subsubsection{Position der Interest Points}
Interest Points stellen besonders markante, in einer lokalen Umgebung möglichst einzigartige Bildpunkte dar. Punkte, an denen sich im DoG-Bild ein lokales Minimum oder Maximum befindet, sind somit gute Kandidaten für Interest Points. Die Extrema werden in jeder Oktave der DoG-Bildpyramide gesucht. Für jedes Pixel werden dafür die umliegenden Nachbarn derselben, sowie der darüber und darunter liegenden Ebene betrachtet.\\
Um die Position des Extremums noch exakter - also im Subpixelbereich - zu bestimmen, wird danach noch eine Taylorapproximation durchgeführt.\\
Extrempunkte die wenig Kontrast aufweisen oder eine Kante darstellen, werden an dieser Stelle wieder verworfen. 



\subsubsection{Umgebungsorientierung der Keypoints}
Um Rotationsinvarianz der Keypoint-Deskriptoren zu gewährleisten, wird zusätzlich zur Keypoint-Position die Richtung maximaler Änderung, also der Gradient, der Umgebung um den Keypoint gespeichert. Die einzelnen Bestandteile des Deskriptors umfassen auch einige Orientierungen, welche nun relativ zur Grundorientierung der Umgebung definiert werden können.\\
Um die dominante Umgebungsorientierung zu beschreiben werden innerhalb eines Fensters um den Keypoint für alle Pixel die Gradienten (als Vektoren definiert durch Magnitude und Winkel) ihrer unmittelbaren 4er-Nachbarschaft bestimmt. Diese werden dann je nach ihrer Orientierung  klassifiziert (hier in 36 Teile der vollen Umdrehung von 2pi radian) und die Magnituden aller Gradienten einer Klasse (bin) aufsummiert, es wird also ein Histogramm erstellt. Dabei werden die Beiträge der Magnituden nach Gauss'scher Gewichtung um den Keypoint verteilt, sodass weiter entfernte Gradienten weniger ins Gewicht fallen. Die nach Magnitude dominante Klasse definiert nun die Orientierung der Umgebung.\cite{lowe04}

\subsubsection{Keypoint-Deskriptoren}
Um die Korrespondenzanalyse zweier Keypoints unter hunderten weiteren und unter Umständen sehr ähnlichen Keypoints zu ermöglichen, muss jeder Keypoint möglichst eindeutig beschrieben sein. Die Deskriptoren durch welche die Keypoints beschrieben werden müssen aber auch eine gewisse Redundanz aufweisen, da sich korrespondierende Keypoints in anderen Bildern (hier in Aufnahmen derselben Szene mit anderen Einstellungen) in der Regel in Nuancen voneinander unterscheiden (Helligkeitsunterschiede, Verdeckungen, Verzerrungen, etc.). Neben einer gewissen Toleranz in der Korrespondenzanalyse (Matching) ist es daher wichtig, die Definition der für den Vergleich relevanten Grundstruktur in mehrere Teile aufzuspalten, die jeweils einen Beitrag zur Akzeptanzwahrscheinlichkeit des Keypoints liefern, sodass die Grundstruktur auch bei Abweichungen in einzelnen Teilen noch erkannt werden kann.\\
Bei SIFT werden daher die Deskriptoren durch Histogramme der Gradientenmagnituden nach 8 Orientierungsklassen (also ähnlich wie bei der Bestimmung der Umgebungsorientierung) aus 16 4*4-Fenstern um den Keypoint herum definiert. Das heißt für 16 Fenster gibt es jeweils 8 Klassen in denen Magnituden aufsummiert werden, die Definition eines SIFT-Deskriptors umfasst somit 128 Elemente.\cite{lowe04}

\subsection{Matching} 
Nun müssen Keypoints, die denselben Interest Point beschreiben, einander zugewiesen werden. Wie bei Lowe\cite{lowe04} wird dazu der Nearest-Neighbor-Ansatz gewählt.\\
Allerdings wird statt der euklidischen Distanz der Winkel zwischen den Deskriptor-Vektoren der entsprechenden Keypoints zwischen den Vektoren minimiert. Dieser lässt sich leicht aus dem Skalarprodukt der beiden Vektoren ermitteln. Für jeden Deskriptor des ersten Bildes können die entsprechenden Skalarprodukte für alle Deskriptoren des zweiten Bildes mittels einer einzigen Vektor-Matrix-Multiplikation berechnet werden.\\
Um die Eindeutigkeit der Zuweisung zu garantieren, wird der kleinste Winkel mit dem zweitkleinsten verglichen\cite{lowe04}. Nur wenn deren Verhältnis unter einem Schwellwert liegt, wird die Zuweisung akzeptiert.\\
Zusätzlich wird überprüft, ob der Deskriptor mit minimalem Winkelabstand bereits einem zuvor betrachteten Deskriptor zugewiesen wurde. In diesem Fall wird dieser durch den aktuellen Deskriptor ersetzt.\\

\subsection{Homographische Transformation}
Um die beiden Bilder zu einem Bild zusammenzuführen, muss eine Homographie-Matrix $H$ ermittelt werden, die die Koordinaten der Bildpunkte eines Bildes in entsprechende Koordinaten im Koordinatensystem des anderen Bildes umwandelt. Dies gilt insbesondere für Keypoint-Paare, also $X_2=H\cdot X_1$ für ein Keypoint-Paar $(X_1,X_2)$. $H$ wird mithilfe des Random Sample Consensus-Algorithmus\cite{dubrovsky09} berechnet.\\
Die Information über die Koordinaten der Keypoint-Paare wird verwendet, um ein lineares Gleichungssystem aufzustellen, dessen Lösung die Koeffizienten der Matrix $H$ liefert. Dafür werden vier Keypoint-Paare benötigt.\cite{kriegman07}\\
Der RANSAC-Algorithmus wählt diese in jedem Iterationsschritt - deren Anzahl wird zuvor festgelegt - zufällig aus und berechnet die zugehörige Matrix $H$. Daraufhin wird die Homographie auf alle zu einem Keypoint-Paar $(X_1,X_2)$ gehörigen Punkte $X_1$ angewendet. Liegt der transformierte Punkt innerhalb eines Toleranzbereichs um den Punkt $X_2$, wird er als \textit{Inlier} bezeichnet. In jedem Iterationsschritt, also für jedes $H$, wird die Anzahl der Inlier berechnet. Am Ende wird die Matrix mit den meisten Inliers als Homographie-Matrix gewählt.\\
Da eine korrekte Lösung des oben beschriebenen Gleichungssystems stark von Ursprung und Skalierung des Koordinatensystems der Bilder abhängt, werden die Koordinaten der Keypoint-Paare zuvor normalisiert. Um die endgültige Homographie-Matrix zu erhalten, wird die Matrix $H$ am Ende noch mit den entsprechenden Transformationsmatrizen multipliziert.\cite{dubrovsky09}

\subsection{Image Stitching}
Das Bildmosaik wird erstellt, indem das rechte Bild, $imB$, mithilfe der Homographie ins Koordinatensystem des linken Bildes, $imA$, transformiert wird. Um durch gerundete Daten entstehende Löcher zu vermeiden, wird dafür zunächst die Lage des transformierten Bildes im neuen Koordinatensystem ermittelt, indem die Ecken von $imB$ transformiert werden. Damit kann die Größe des Bildmosaiks berechnet werden.\\
Nun wird $imA$ entsprechend erweitert und eine Maske von derselben Größe erstellt, die die Region für das transformierte $imB$ enthält. Für diese Region werden anschließend mithilfe der inversen Homographie die entsprechenden Bildwerte berechnet. \\
Für das naive Splining wird schließlich das Bildmosaik mittels $I_{Mosaik}=(1-I_{Maske})\cdot I_{A,erweitert} + I_{Maske}\cdot I_{B,tranformiert+erweitert}$ erstellt. \\
Für das Multiresolution Splining\cite{spline83} werden von beiden (erweiterten bzw transformierten) Bildern sowie der Maske Laplacepyramiden erstellt.Dadurch wird der Frequenzbereich in einzelne Bandbreiten von einer Oktave aufgeteilt. Nun wird auf jeder Ebene wie beim naiven Splining ein Bildmosaik zusammengesetzt. Am Ende werden die Bilder der Mosaikpyramie schließlich zu einem Mosaik zusammengefügt.

%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\section{Implementierung}
(1-X Seiten)\\
Hier gebt ihr einen Überblick über eure Implementierung:\\
Wie habt ihr die im vorhergehnden Abschnitt vorgestellte Methodik praktisch umgesetzt? Wie werden die einzelnen Methoden kombiniert (zB. Implementierungspipeline)?\\
Hier ist Platz für Implementierungsdetails wie zB. gewählte Parameter. \\
Wie startet der User das Programm? Welche Parameter hat der User zu setzen?\\
Auch in diesem Abschnitt können Referenzen und Zitate notwendig sein.\\\\
Die in Abschnitt 3 (Methodik) beschriebene Funktionalität ist in Matlab-Funktionen gegliedert und in main.m zur kompletten Image-Stitching-Pipeline zusammengefügt. Der Prozess wird durch main('Pfad zum linken Bild', 'Pfad zum rechten Bild') gestartet. Optional kann eine grafische Oberfläche mittels Aufruf von GUI.m verwendet werden. Alle notwendigen Schritte sind in dieser erklärt.\\
Um vor dem Endresult, also dem gestitchten Bild, die gefundenen Keypoints oder das Matching der Keypoints beider Bilder ausgeben zu lassen, können die Funktionen showKeypoints.m und showMatches.m. In main.m können dazu einfach die Zeilen mit 'showKeypoints' und 'showMatches' dekommentiert werden.\\\\
Für ein reibungsloses Zusammenspielen der einzelnen Komponenten sind in den Funktions-Headern die Schnittstellen definiert, also das Format der Parameter und Rückgabewerte beschrieben. Für genauere Information zu den einzelnen Funktionen sind daher diese heranzuziehen.\\\\
TODO\\
%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\section{Evaluierung}
(2-X Seiten)\\
Hier stellt ihr euren Datensatz vor und beantwortet Evaluierungsfragen:\\
z.B. Fakten zum Datensatz: Anzahl der Bilder, Größe der Bilder, Quelle des Datensatzes (falls selbst aufgenommen: Aufnahmegerät, Einstellungen,... / falls nicht selbst erstellt: Datenbank vostellen...)\\
Diskussion der Evaluierungsfragen: Beantwortung der Fragen, Diskussion anhand von Beispielen, Diskussion von Grenzfällen: für welche Bilder funktioniert die Implementierung, für welche nicht? Worin unterscheiden sich diese Bilder? etc.
%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\section{Schlusswort}
(max. 1 Seite)\\
Hier fasst ihr Ergebnisse eures Projekt zusammen:\\
Welche Schlussfolgerung lässt sich ziehen? Gibt es offene Probleme? Wie lässt sich eure Lösung noch verbessern? etc.
%%------------------------------------------------------

%%------------------------------------------------------
\newpage
\bibliographystyle{plain}
\bibliography{edbv_lit}
%%Bei verwendung von Latex schreibt ihr eure Referenzen in ein eigenes bib-File (siehe hier edbv_lit.bib). Jene Referenzen, die ihr im Bericht mittels \cite zitiert, werden automatisch in die Referenzliste übernommen. Weitere Information zum Einbinden von BibTex gibt es hier: http://www.bibtex.org/Using/de/
%%------------------------------------------------------

\end{document}
